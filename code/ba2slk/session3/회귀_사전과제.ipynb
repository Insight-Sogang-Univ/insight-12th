{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb984c5-0ac0-47d8-bf4c-e1d54aed84d0",
   "metadata": {},
   "source": [
    "# 회귀 사전과제\n",
    "\n",
    "## 머신러닝\n",
    "1. 비지도 학습: 정답이 없는 데이터로 학습 (군집화, 클러스터링)\n",
    "2. 지도 학습: 정답이 있는 데이터로 학습 (회귀, 분류)\n",
    "3. 머신러닝: 새로운 데이터를 예측하거나 결정을 내릴 수 있도록 하는 기술. 데이터의 패턴을 찾고, 패턴을 바탕으로 새로운 대에터에 대한 예측을 가능하게 함. (Model Based, Model Free)\n",
    "\n",
    "## 모델링\n",
    "전체 데이터(훈련 데이터 | 테스트 데이터 -> 데이터 분리)\n",
    "훈련 데이터 -> 모델 -> 성능 평가 (훈련 데이터로부터 만든 모델을 테스트 데이터로 반복 성능 평가)\n",
    "테스트 데이터 -> 성능 평가\n",
    "전체 데이터 -> 최종 모델\n",
    "\n",
    "### 전체 데이터\n",
    "- 훈련 데이터 (train_set): 모델 학습 시킬 때 쓰는 데이터\n",
    "- 테스트 데이터 (test_set): 학습된 모델을 검증하기 위해 사용하는 데이터\n",
    "\n",
    "train data를 통해 학습한 모델이 얼마나 잘 예측하는지 **공정하게 평가**하기 위해서 데이터를 분리! 분리하지 않고 전부 다 학습시키면 '예측'이 아닌 '암기'. (우리는 예측이 하고 싶음)\n",
    "\n",
    "## 회귀\n",
    ": 데이터의 **패턴**으로부터 미래의 값을 **예측**하는 것.<br>\n",
    "=> 주로 연속적인 숫자를 다룸\n",
    "\n",
    "- 종류: 선형, 비선형, 로지스틱, 릿지, 라쏘, 다항...\n",
    "\n",
    "### 선형회귀\n",
    ": 데이터를 가장 잘 설명하는 **회귀선**(직선y=ax+b)을 찾아 **예측**하는 과정.<br>\n",
    "- 종속변수 = 예측하고자 하는 것 = y\n",
    "- 독립변수 = 예측에 사용하는 변수 = x\n",
    "> x에 따른 y를 예측\n",
    "\n",
    "#### 단순 선형 회귀\n",
    ": 데이터를 직선 형태(하나의 독립변수)로 표현\n",
    "\n",
    "- 단순 = '하나'의 독립변수만 존재하는 선형 회귀<br>\n",
    "`y=ax + b`<br>\n",
    "- a: 회귀계수(기울기)\n",
    "- b: y절편\n",
    "\n",
    "즉, `적절한 회귀계수와 절편을 찾는 과정`임.\n",
    "\n",
    "##### How?\n",
    "- 최적의 회귀선 찾는 방식: 최소 제곱법, 최소자승법<br>\n",
    "=> 잔차(예측값-실제값)의 제곱의 합이 최소가 되는 지점.\n",
    "\n",
    "- 핵심 = 회귀선과 실제 데이터와의 차이를 최소화하기 위한 시도.\n",
    "\n",
    "#### 다중 선형 회귀\n",
    ": 데이터를 두 개 이상의 독립변수를 사용하여 표현\n",
    "\n",
    "- 다중 = '2개 이상'의 독립변수\n",
    "- 최소제곱법 사용 가능 =? 이때 잔차 = 관측치와 평면간의 차이 \n",
    "\n",
    "**다중공선성**<br>\n",
    ": 회귀 분석에 독립 변수들 간 상관관계가 큰 경우 발생<br>\n",
    "=> 다중공선성이 높은 경우 어떤 독립변수가 종속 변수에 얼마나 영향을 미치는지 정확하게 구분하기 어려움. 따라서 회귀 모델은 어떤 변수의 영향을 반영해야 할지 불확실해지고, 그 결과 회귀분석의 정확도가 낮아짐.\n",
    "\n",
    "<확인 방법>\n",
    "1) 상관계수: 상관관계의 정도를 수치로 나타낸 것.<br>\n",
    "=> (-1 < _ < 1) 양 극단에 가까울 수록 상관성 높음. 음(양)수 => 음(양)의 상관관계. 0은 상관관계 없음.\n",
    "\n",
    "2) 히트맵 또는 corr() 사용\n",
    "\n",
    "3) VIF 지수<br>\n",
    ": 분산 팽창 인수, 회귀 모델의 결정계수 R square를 사용하여 계산됨.\n",
    "- VIF = 1: 상관관계 없음.\n",
    "- VIF < 5: 다중공선성 문제 없음.\n",
    "- VIF > 5: 다중공선성 징후 있음. 주의 요망.\n",
    "- VIF > 10: 다중공선성 심각. 회귀 모델 불안정성 의미. -> 해당 변수 제거 또는 변수 간 상관관계를 줄이기 위한 조치 필요.\n",
    "\n",
    "<대처 방법>\n",
    "1. 변수 제거: 독립변수로서 사용할 변수 선택\n",
    "2. 변수 변환: 변수 간 연산 -> 새로운 변수 생성.\n",
    "3. 규제 선형 모델 활용: 릿지, 라쏘, 엘라스틱넷 -> **모델 복잡도** 줄이기\n",
    "4. PCA 주성분분석: 데이터의 차원 축소에 사용되는 통계 기법. 고차원 데이터에서 중요한 정보를 최대한 보존하면서 **데이터의 복잡성**을 줄이는 것이 목표.\n",
    "\n",
    "## 모델 평가 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77306ba3-73dc-46fc-b534-ef1557dc5245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
