{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09f9225-bcf8-4f9c-a325-605abad60d00",
   "metadata": {},
   "source": [
    "## 분류 기초 사전과제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969e2f6-b43c-48df-8ea7-26fd554535f3",
   "metadata": {},
   "source": [
    "### **1. 지도 학습과 비지도 학습의 차이**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f0f6ac-1bac-4538-8a82-7b7dcebb9114",
   "metadata": {},
   "source": [
    "#### [머신러닝]\n",
    "컴퓨터가 스스로 어떠한 판단 혹은 예측을 할 수 있도록 학습시키는 것 <br>\n",
    "머신러닝의 종류로 지도 학습, 비지도 학습이 있음 <br>\n",
    "\n",
    "**지도 학습**\n",
    "- 회귀, 분류\n",
    "- 정답이 있는 데이터\n",
    "- 예측값 = 정답이 되도록 기계를 학습시키는 것 \n",
    "- ex) 수많은 기린, 고양이의 사진을 주고 하나하나 정답 알려주며 학습시킴\n",
    "\n",
    "**비지도 학습**\n",
    "- 군집화\n",
    "- 정답이 없는 데이터\n",
    "- 데이터의 패턴, 데이터의 유사도 기계가 학습하도록 하는 것\n",
    "- ex) 정답을 알려주지 않았지만 노랗고 얼룩이 있고 목이 긴 동물을 기린, 꼬리가 길고 귀가 뾰족한 동물을 고양이라고 학습하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54be2f-3ffa-44f2-bfc2-f5815f378f02",
   "metadata": {},
   "source": [
    "### **2. 회귀와 분류의 차이**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50849059-bc4c-43b1-bdef-7468b66fc753",
   "metadata": {},
   "source": [
    "회귀와 분류는 모두 지도 학습의 종류 <br>\n",
    "예측값과 정답이 최대한 같아지도록 학습 <br>\n",
    "(독립변수, 종속변수가 모두 존재하는 데이터를 train set, test set으로 나눔 -> <br>\n",
    "train set에서 독립변수를 통해 추정한 예측값이 주어진 종속변수와 같아지도록 모델 훈련) \n",
    "\n",
    "**회귀**\n",
    "- 종속 변수가 연속형일 때 사용\n",
    "- 회귀선 찾기 (X를 기반으로 Y를 가장 잘 설명하는 것)\n",
    "\n",
    "**분류**\n",
    "- 종속 변수가 범주형일 때 사용\n",
    "- 기존 데이터가 어떤 레이블에 속하는지 패턴 인지 후 새로운 데이터 레이블 판별\n",
    "- 대표적인 알고리즘 : 로지스틱 회귀, 결정 트리, 서포트 벡터 머신, 최소 근접 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e26a9b-8d1e-4451-ad87-841df80872b8",
   "metadata": {},
   "source": [
    "### **3. 분류 모델의 네 가지 종류**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2772ecdb-d387-4414-8f18-8753f1855d5e",
   "metadata": {},
   "source": [
    "**(1) 로지스틱 회귀**\n",
    "- 이진 분류 문제 해결에 적합 (ex. 이메일 스팸인지 아닌지, 환자가 병 있는지 없는지) \n",
    "- 독립변수의 선형 회귀에 로지스틱 함수 적용 - 출력값 0~1 사이 변환\n",
    "- 직선은 분류 문제에 적합 X, 시그모이드 함수 (곡선) 사용하여 안정적 예측 필요\n",
    "- 시그모이드 함수 : S자 형태, 출력 0~1 사이 값\n",
    "- 출력값이 특정값 이상이면 1, 이하면 0\n",
    "- 주어진 데이터에 적합한 가중치 ($w$, $b$) 구하는 것\n",
    "\n",
    "**(2) 결정 나무**\n",
    "- 조건에 따라 데이터 분류, 최종적으로 순수한 label의 집합으로 구성될 때까지 반복\n",
    "- 시각화 통해 분류 잘 이루어졌는지 확인 가능 (과적합 여부 등)\n",
    "- 가지치기 (불필요한 노드 지우기) : 노드 많으면 과적합 확률 높으므로 하부 트리 제거하여 성능 높이기  \n",
    "\n",
    "CART 알고리즘\n",
    "- 임계값 기준으로 데이터셋 두 child로 나눔\n",
    "- 불순도(지니 계수, 서로 다른 범주가 섞여 있는 정도) 낮아지는 방향으로 임계값 나눔\n",
    "- 지니계수=0일 때 가장 순수도 높음\n",
    "- 한계 : 당장의 지니계수 낮추는 판단만 함 - 효율적인 대안 제시 불가\n",
    "\n",
    "**(3) 서포트 벡터 머신 (SVM)**\n",
    "- 클래스를 분류할 수 있는 다양한 경계선 중 최적의 라인 찾아내는 알고리즘\n",
    "- 고차원 공간에서도 효과적으로 사용 가능\n",
    "- Support vector : 구분선과 가장 가까운 point\n",
    "- Decision Boundary : 집단 구분하는 선\n",
    "- Margin : 선과 각 점의 거리 (가장 큰 경우가 최적의 선!)\n",
    "\n",
    "**(4) KNN**\n",
    "- 데이터로부터 거리가 가까운 k개의 다른 데이터 레이블 (이웃) 기반으로 분류\n",
    "- 데이터 준비 - K값 설정 (홀수개) - 거리 계산 - 이웃 선택 - 분류\n",
    "- 별도의 모델 없이 주변 데이터만을 활용하여 분류 가능\n",
    "- 장점 : 훈련 필요 X, 정보 손실 X\n",
    "- 단점 : 쿼리 처리 시간 소요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39679bd7-4020-40e0-bc40-096ab7679ac7",
   "metadata": {},
   "source": [
    "### **4. 분류 평가 지표**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b915eeb-7af9-4fb4-ad40-df16f3810295",
   "metadata": {},
   "source": [
    "**(1) 혼동 행렬**\n",
    "- 분류 모델의 예측 결과를 정확한 예측, 잘못된 예측으로 구분하여 나타낸 표\n",
    "- 실제/예측 순서 -> TF(참,참) / TN(거짓,거짓) / FP(거짓,참) / FN(참,거짓)\n",
    "\n",
    "정확도 (Accuracy)\n",
    "- 모든 가능한 예측 중 참인 비율\n",
    "- TP+TN / TP+TN+FP+FN\n",
    "\n",
    "정밀도 (Precision)\n",
    "- 참이라고 예측한 경우 실제 참의 비율\n",
    "- TP / TP+FP\n",
    "\n",
    "재현도 (Recall)\n",
    "- 실제로 참인 경우 중 참으로 예측하는 비율\n",
    "- TP / TP+FN\n",
    "\n",
    "** 정밀도, 재현도는 Trade-off 관계 <br>\n",
    "Threshold 낮춤 - Recall 증가, Precision 감소 <br>\n",
    "Threshold 높임 - Recall 감소, Precision 증가 <br>\n",
    "-> 두 value 값이 만나는 지점 Threshold로 정하면 예측 오류 최소화 가능 \n",
    "\n",
    "\n",
    "**(2) F1-Score**\n",
    "- 정밀도(Precision), 재현율(Recall) 의 조화 평균\n",
    "- 2 * Precision * Recall / Precision+Recall\n",
    "\n",
    "**(3) ROC / AUC Curve**\n",
    "\n",
    "ROC Curve\n",
    "- 얼마나 분류 잘 되었는지 보여주는 그래프\n",
    "- TPR : 참인 것들 중 참이라고 예측한 비율 (Recall)\n",
    "- FPR : 거짓인 것들 중 참이라고 잘못 예측한 비율\n",
    "\n",
    "AUC Curve\n",
    "- ROC와 x축 사이의 면적\n",
    "- 0~1 사이의 값 가짐, 1에 가까울수록 분류 성능 좋음 \n",
    "\n",
    "**다중 분류 평가 지표**\n",
    "- 이진 분류 평가 지표를 사용하여 클래스별 점수 구한 뒤 평균 내는 것\n",
    "- Macro average : 클래스별로 구한 평가 지표 평균, 모든 클래스에 동등한 가중치\n",
    "- Weighted average : 클래스별로 구한 평가 지표 가중평균, 빈도 높은 클래스에 더 큰 가중치\n",
    "- Micro average : 모든 클래스의 예측 결과 더하여 전체적인 성능 평가, 모든 클래스에 동등한 가중치 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e3b86-4e39-49fe-9daa-41dc0bcb7631",
   "metadata": {},
   "source": [
    "### **5. 하이퍼파라미터 최적화**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7c75d-d6ba-4648-85f6-2e557d8cff07",
   "metadata": {},
   "source": [
    "#### [하이퍼파라미터]\n",
    "학습 시작 전 사용자가 직접 설정하는 변수 <br>\n",
    "적절한 하이퍼파라미터를 찾아 모델 성능 향상시키는 것이 최적화! <br>\n",
    "[탐색 범위 설정 - 평가 지표 계산 함수 정의 - 검증 데이터로 정확도 평가 - 반복하며 범위 좁힘] <br>\n",
    "\n",
    "**최적화 방법** <br>\n",
    "\n",
    "(1) Grid Search\n",
    "- 정해진 범위에서 하이퍼파라미터 모두 순회\n",
    "- GridSearchCV\n",
    "- 장점 : 정확도 높음\n",
    "- 단점 : 시간 오래 걸림\n",
    "- 넓은 범위, 큰 step 활용\n",
    "\n",
    "(2) Random Search\n",
    "- 정해진 범위에서 하이퍼파라미터 무작위 탐색\n",
    "- RandomSearchCV\n",
    "- 장점 : 속도 빠름 (Grid Search보다)\n",
    "- 단점 : 정확도 떨어짐\n",
    "\n",
    "(3) Bayesian Optimization\n",
    "- 사전 정보 바탕으로 최적 하이퍼파라미터 값 확률적으로 추정, 탐색\n",
    "- bayes_opt\n",
    "- Aquisition Function 적용했을 때 가장 큰 값 나올 확률이 높은 지점 찾기\n",
    "\n",
    "\n",
    "**최적화 검증**\n",
    "- 성능 평가 시 검증 데이터 사용\n",
    "- Optuna 활용 - 하이퍼파라미터 최적화 자동화"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
