{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b120ea12",
   "metadata": {},
   "source": [
    "# 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84705e4c",
   "metadata": {},
   "source": [
    "- 비지도학습: 정답이 없는 데이터로 학습하는 방식\n",
    "- 지도학습: 정답이 있는 데이터로 학습하는 방식\n",
    "- 머신러닝: 새로운 데이터를 예측하거나 결정을 내릴 수 있도록 하는기술<br>\n",
    "                머신러닝을 통해 데이터에서 패턴을 찾아내고, 패턴을 바탕으로 새로운 데이터 예측 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59baf1",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364cbef3",
   "metadata": {},
   "source": [
    "- 머신러닝 모델을 생성하는 과정을 모델링이라고 함\n",
    "- 훈련 데이터(train_set): 모델을 학습시킬 때 쓰이는 데이터\n",
    "- 테스트 데이터(test_set): 학습된 모델을 검증하기 위해 사용하는 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3858880",
   "metadata": {},
   "source": [
    "# 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31cd9ad",
   "metadata": {},
   "source": [
    "- 데이터에서 패턴을 찾아내어 미래 값을 예측하는 것\n",
    "- 통계나 머신러닝의 주요 개념\n",
    "- 연속적인 숫자를 다룸\n",
    "- 종류: 선형회귀, 비선형 회귀, 로지스틱 회귀, 릿지, 라쏘, 다항회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f283ea4",
   "metadata": {},
   "source": [
    "## 선형회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d3dae",
   "metadata": {},
   "source": [
    "- 데이터를 가장 잘 설명하는 회귀선(ex. y=ax+b)을 찾아 예측하는 과정\n",
    "- 예측하고자 하는 것을 종속 변수 예측을 위해 사용하는 변수를 독립 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de5ef8",
   "metadata": {},
   "source": [
    "1. 단순 선형 회귀\n",
    "- 데이터를 직선 형태로 표현하는 경우\n",
    "2. 다중 선형 회귀\n",
    "- 데이터를 두 개 이상의 독립 변수를 사용하여 표현하는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b7c31",
   "metadata": {},
   "source": [
    "## 단순선형회귀분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943a99f",
   "metadata": {},
   "source": [
    "- 하나의 독립변수만 존재하는 선형 회귀이다.\n",
    "- 데이터를 가장 잘 설명하는 직선 y=aX+b을 찾는 과정\n",
    "- y=aX+b에서 a는 회귀계수(기울기)b는 y절편을 의미\n",
    "- 적절한 회귀계수(a)와 절편을 찾는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b6b93",
   "metadata": {},
   "source": [
    "### 최적의 회귀선 찾는 방식: 최소 제곱법, 최소자승법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c7fd9",
   "metadata": {},
   "source": [
    "- 잔차의 제곱의 합이 최소가 되는 지점으로 최적의 회귀선을 구하는 방식\n",
    "- 잔차: 실과 예측값의 차이\n",
    "- 핵심: 회귀선과 실제 데이터와의 차이를 최소화하기 위한 시도\n",
    "- 최소 제곱법을 통해 구한 함수가 복잡하여 최솟값을 구하기 어려울 때 보통 경사하강법 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723760a5",
   "metadata": {},
   "source": [
    "## 다중선형회귀분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb00caa",
   "metadata": {},
   "source": [
    "- 독립 변수가 2개 이상인 경우의 선형회귀\n",
    "- 독립 변수가 2개인 경우 3차원 공간에 표현됨. 회귀선은 평면이 됨\n",
    "- 최소제곱법 사용 가능. 이 때, 관측치와 평면간의 차이가 잔차가 됨\n",
    "- 변수가 2개보다 많은 경우는 비슷한 느낌으로 확장됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1854c3e",
   "metadata": {},
   "source": [
    "### <span style = \"color: blue\">다중공선성</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd50471",
   "metadata": {},
   "source": [
    "- 회귀 분석에서 독립 변수들 간에 상관관계가 큰 경우 발생함\n",
    "- 변수들끼리 겹치는 상황\n",
    "- 다중공선성이 높은 경우 어떤 독립 변수가 종속 변수에 얼마나 영향을 미치는지 정확하게 구분이 어려움\n",
    "- 회귀모델은 어떤 변수의 영향을 반영해야 할지 불확실해지고, 그 결과 회귀분석의 정확도 낮아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d805ec9",
   "metadata": {},
   "source": [
    "### <span style = \"color: blue\">다중공선성 확인 방법</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67075fb",
   "metadata": {},
   "source": [
    "#### <span style = \"color: red\">VIF지수</span>\n",
    "\n",
    "- 분산 팽창 인수, 회귀 모델의 결정계수 R square를 사용하여 계산됨\n",
    "- VIF가 1이면 해당 독립 변수는 다른 변수와 상관관계가 전혀 없음을 의미\n",
    "- VIF 5보다 작으면 다중공선성 문제 없음\n",
    "- VIF 5보다 크면 다중공선성 징후 있음(*주의*)\n",
    "- VIF 10보다 크면 다중공선성 심각"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb45bdae",
   "metadata": {},
   "source": [
    "### <span style = \"color: blue\">다중공선성 대처 방법</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06884fe5",
   "metadata": {},
   "source": [
    "1. 변수 제거\n",
    "- 말그대로 독립변수로서 사용할 변수를 선택하는 방법\n",
    "2. 변수 변환\n",
    "- 변수들을 더하거나 빼서 새로운 변수 생성\n",
    "- 독립변수를 더하거나 빼더라도 문제가 없는 경우\n",
    "3. 규제 선형 모델 활용:\n",
    "- 릿지,라쏘,엘라스틱넷 등의 방법을 통해 모델의 복잡도를 줄이는 방법 사용\n",
    "4. PCA(주성분분석)\n",
    "- 데이터의 차원을 축소하는 데 사용되는 통계적 기법\n",
    "- 고차원 데이터에서 중요한 정보를 최대한 보존하면서 데이터의 복잡성을 줄이는 것이 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f159385",
   "metadata": {},
   "source": [
    "# 모델 평가방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f095ba",
   "metadata": {},
   "source": [
    "## 성능 평가 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f137ba8",
   "metadata": {},
   "source": [
    "1. 평균 제곱 오차(MSE)\n",
    "- 회귀 분석에서 모델의 예측값과 실제 관측값 사이의 오차 제곱의 평균을 의미\n",
    "- 모델의 예측 성능을 평가하는 지표\n",
    "2. 평균 절대 오차(MAE)\n",
    "- 회귀 분석에서 모델의 예측값과 실제 관측값 사이의 절대값 오차의 평균\n",
    "- 모델의 예측 성능을 평가하는 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd627e1c",
   "metadata": {},
   "source": [
    "## 변수 유성 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48d2a7",
   "metadata": {},
   "source": [
    "1. t검정\n",
    "- 독립 변수의 회귀계수가 0인지 아닌지 가설 설정\n",
    "- 유의성이 크면 종속 변수에 영향을 주는 변수라고 판단\n",
    "- p-value가 0.05보다 작으면 해당 변수는 유의하다고 판단"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
