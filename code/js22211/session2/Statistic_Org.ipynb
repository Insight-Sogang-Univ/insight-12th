{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc137544-b7cc-4f4b-ab05-b7e0064d339f",
   "metadata": {},
   "source": [
    "# Session 3 Statistic\n",
    "## 1. 통계란?\n",
    "다양한 현상과 정보 수집 --통계-> 패턴 발견, 미래 예측\n",
    "종류 1. 기술 통계 2. 추론 통계 <br>\n",
    "## 2. 기술 통계\n",
    "### 2.1 중심 위치 척도\n",
    "- 평균 <br>\n",
    "    데이터의 중심 경향성을 나타낸다. 이상치에 민감 <br>\n",
    "    series.mean()\n",
    "- 중앙값 <br>\n",
    "    가운데에 위치한 값. 이상치에 덜 민감 <br>\n",
    "    series.median()\n",
    "- 최빈값 <br>\n",
    "    데이터에서 가장 자주 나타나는 값 <br>\n",
    "    discrete data에서 자주 나타남 <br>\n",
    "    series.mode()\n",
    "- Skew <br>\n",
    "    positive skewness, negative skewness, normal distribution <br>\n",
    "    series.skew()\n",
    "### 2.2 변동성 척도\n",
    "튜키 펜스를 이용해서 설명\n",
    "- 사분위수 <br>\n",
    "데이터의 표본을 4개의 동일한 크기로 나눈 값<br>\n",
    "np.percentile(arr, 25) # Q1 <br>\n",
    "np.percentile(arr, 50) # Q2 <br>\n",
    "np.percentile(arr, 75) # Q3 <br>\n",
    "- 사분위 간 범위 (IQR) <br>\n",
    "Q3에서 Q1 값을 제외한 범위. 데이터의 중앙 분포를 나타냄. 이상치 판단 쉬움\n",
    "- 범위 <br>\n",
    "np.max(arr)- np.min(arr)\n",
    "- 분산 (variance) <br>\n",
    "데이터들이 얼마나 흩어져 있는지를 나타낸다.\n",
    "np.var(arr)\n",
    "- 표준편차 (standard deviation) <br>\n",
    "분산의 단위는 관측값 단위의 제곱이 된다. 표준편차가 분산보다 훨씬 직관적임<br>\n",
    "np.std(arr)\n",
    "- 변동계수 (coefficient of variation)<br>\n",
    "상대적 변동성을 나타낸다. 표준편차를 데이터의 평균으로 나눈 값임. 표준편차는 단위 존재. 변동계수는 단위 없으므로 서로 다른 집단들의 비교가 용이함.<br>\n",
    "np.std(arr)/ np.mean(arr)*100\n",
    "### 2.3 연관성 척도\n",
    "- 공분산 (covariance)<br>\n",
    "두 변수가 함께 어떤 방향으로 변화하는지와 그 크기를 표현하는데 사용된다. <br>\n",
    "pos : 양의 관계 neg : 음의 관계 0 : 양도 음도 아닌 관계 <br>\n",
    "np.cov(df['col1'],df['col2'])\n",
    "- 상관계수 <br>\n",
    "두 변수 간 선형적인 관계를 나타내는 통계적 지표 <br>\n",
    "상관관계 vs 인과관계 <br>\n",
    "상관관계 : 수치적으로 연관성이 있는 관계 <br>\n",
    "인과관계 : 한 변수가 다른 변수를 발생시키는 관계\n",
    "## 3. 추론 통계 1 (모집단 분포 추정)\n",
    "모집단과 표본집단 : 모집단은 전체, 표본집단은 전체에서 임의로 추출한 일부<br>\n",
    "대수의 법칙 : 데이터 다다익선<br>\n",
    "중심극한정리 : 크면 정규분포와 비슷\n",
    "### 3.1, 3.2 확률 분포와 종류\n",
    "확률분포 : 확률변수가 특정한 값을 가질 확률Mbr>\n",
    "종류 : 이산확률분포, 연속확률분포, 정규분포, T분포, 카이제곱분포<br>\n",
    "- 정규분포 (Normal Distribution)\n",
    "- T 분포 <br>\n",
    "변수는 자유도. 표본으로 모평균을 추정할 때 사용되는 분포, 표본 크기가 작을 때 정규분포보다 더 정확한 결과를 제공하므로 사용한다. <br>\n",
    "자유도란 얼마나 많은 정보가 독립적으로 변할 수 있는가?<br>\n",
    "오버피팅이란? 자유도가 낮아 새로운 데이터에 대한 일반화 성능이 저하되는 현상\n",
    "- Chi-Square Distribution<br>\n",
    "0에서 시작하여 오른쪽으로 긴 꼬리를 가진 비대칭\n",
    "자유도가 증가함에 따라 중심이 오른쪽으로 이동하고 모양이 더 대칭적으로 변화하며, 정규분포에 가까워짐<br>\n",
    "매개변수 : 자유도 <br>\n",
    "## 4. 추론 통계 2 ( 가설 검정 )\n",
    "### 4.1 가설 검정 절차\n",
    "1. 가설 설정<br>\n",
    "    귀무가설 H0, 대립가설 H1 설정<br>\n",
    "    귀무가설 : 주로 기각하고자 하는 명제, 현재 통용되고 있는 가설 ex) ~는 차이가 없다<br>\n",
    "    대립가설 : 내가 주장하고자 하는 명제, 새로 주장하고 싶은 가설 ex) ~는 차이가 존재한다.<br> \n",
    "   - 1, 2종 오류<br>\n",
    "        1종 오류 : 기각하고자 한 귀무가설이 실제로 참이었는데 기각할 확률<br>\n",
    "        2종 오류 : 기각하고자 한 귀무가설을 기각했어야 했는데 기각하지 못할 확률\n",
    "2. 유의수준 설정<br>\n",
    "유의수준 : 정해진 수치를 얼마나 벗어났을 때 귀무가설을 기각할 것인가를 판단하는 기준, 연구자가 결과를 판단할 때 허용할 수 있는 오류의 최대치\n",
    "3. 검정 통계량 산출 <br>\n",
    "가설 검정의 결과를 판단하는데 사용되는 값이다. 데이터의 분포나 특징에 따라 T, F 값 등 어떤 통계량을 사용할지 정해야 한다.\n",
    "- Z값 <br>\n",
    "표준정규분포를 사용해 얻은 값. 특정 데이터가 평균으로부터 얼마나 떨어져 있는지<br>\n",
    "사용처 : 표본의 크기가 클때. 모집단의 평균에 대한 가설을 검정할때 <br>\n",
    "수치해석 : Z값이 크면 -> 평균으로부터 멂. 비이상적, 이상치<br>\n",
    "임계점 찾기 : 고딩 확통 95, 99% 구하기와 유사 Z = 1.96, 2.58일때\n",
    "- T값 <br>\n",
    "T분포를 사용해서 얻은 값. 작은 표본 크기에 유리. t분포는 꼬리부분이 정규분포보다 더 두꺼워 작은 표본에서의 불확실성을 더 잘 반영한다.<br>\n",
    "μ는 연구자가 설정하는 값이므로, 표본 데이터에서 직접 계산되는 값이 아니라 가설에서 기대되는 값이다. T-검정에서 μ는 모집단 평균이 될 가능성이 있는 \"기대값\"을 나타내며, 이를 통해 연구자는 표본 평균과 가설 평균의 차이를 분석할 수 있게 된다.<br>\n",
    "사용 : 모집단의 평균에 대한 가설을 검정, 두 표본 평균 간의 차이를 검정할 때 사용된다.<br>\n",
    "수치 해석 : T값의 절대값이 크면 해당 데이터가 모집단 평균으로부터 멀리 떨어져 있다. 관측된 표본 평균이 모집단 평균과 유의미한 차이가 있는 것을 의미\n",
    "- F값 <br>\n",
    "F분포는 2개의 독립적인 카이제곱 분포된 변수들의 비율로 정의된다. F값은 F분포를 사용하여 얻은 값으로 두 표본 분산 사이의 차이를 비교하는데 사용. <br>\n",
    "수치해석 : 2개의 표본분산의 비이므로 값이 1에 가까우면 두 표본의 분산이 비슷하다는 것을 의미\n",
    "4. 가설 기각 / 채택 판단<br>\n",
    "유의확률(p-value) : 가설 검정에 쓰일 수 있는 또 다른 척도. 검정 통계량에서 유도 가능 p가 유의 수준(α)보다 작을 시에 귀무가설을 기각. 클 시는 기각 못함\n",
    "### 4.2 여러 검증 방법\n",
    "#### [수치형-수치형] 피어슨 상관 분석\n",
    "##### 시각화로 알아보기\n",
    "plt.scatter(df['colx'], df['coly'])<br>\n",
    "sns.pairplot(df)\n",
    "##### 수치화로 알아보기 \n",
    "피어슨 상관 분석이란? 두 변수간 피어슨 상관계수가 얼마나 유의미한지를 검증하는 방법. 즉 귀무, 대립 가설은 다음과 같이 세워진다.<br>\n",
    "H0 : 두 변수간 선형 상관관계 X, H1 : 두 변수간 선형 상관 관계가 존재한다. <br>\n",
    "import scipy.stats as spst<br>\n",
    "spst.pearsonr(df['col1'], df['col2'])<br>\n",
    "주의 :상관계수는 선형 상관 관계만을 파악할 수 있으며, 직선의 기울기 또한 고려하지 않는다. \n",
    "#### [범주형-수치형] F-test(ANOVA), T-test\n",
    "##### 시각화로 알아보기\n",
    "sns.barplot(x = 'col1', y = 'col2', data = df)<br>\n",
    "plt.show()<br>\n",
    "플롯위 검은선은 각 평균의 95% 신뢰구간을 나타낸다. \n",
    "##### 범주가 2개일때 수치화로 알아보기\n",
    "T-test를 사용한다. 이때 t값은 두 평균 간 차이를 표주 오차로 나눈 값이다. <br> \n",
    "가설은 아래와 같이 세워진다. <br>\n",
    "H0 : 두 그룹의 평균엔 차이가 없다, H1 : 두 그룹의 평균에는 차이가 있다. <br>\n",
    "mincho = df.loc[df['민초여부'] == 'Yes', '수명'] <br>\n",
    "no_mincho = df.loc[df['민초여부'] == 'No', '수명' ] <br>\n",
    "spst.ttest_ind(mincho, no_mincho) <br>\n",
    "결과는 TtestResult(statistic = t-값, pvalue = p값, df = 자유도)의 형태로 나온다. t값은 보통 절대값 2를 기준으로 그보다 크면 차이가 있으며 그보다 클수록 차이가 크다고 생각하면 된다. p값은 앞서 언급했듯 결과가 얼마나 믿음직한지를 나타낸다. <br>\n",
    "test_ind : test_independent로 이해. 두 범주가 서로 독립적인 경우.<br>\n",
    "test_rel : test_related. 두 범주가 독립이 아닐 경우를 나타낸다. 다시 말해, 같은 그룹이 시점이 다른 상태로 존재할 때로 생각하면 된다. <br>\n",
    "둘이 분리되어 있는 이유는, 각 경우 t-값을 계산하는 방법이 다르기 때문이다. <br>\n",
    "spst.ttest_rel(before, after) <br>\n",
    "단측 검정을 진행하고 싶다면...? <br>\n",
    "양측 검정은 두 그룹 간 차이가 존재하는가, 단측 검정은 두 그룹 간 차이의 \"한쪽\"만 보고 싶을 때 사용하는 방법이다. <br>\n",
    "t분포는 좌우대칭형이므로, 코드를 똑같이 하되 결과로 나온 p값을 2로 나눈 것이 단측 검정의 결과이다. <br>\n",
    "##### 범주가 3개 이상일 때 수치화로 알아보는 방법\n",
    "t 검정은 범주가 2개일 때 사용할 수 있다. 범주가 3개 이상일 때는 ANOVA(분산분석)을 통해 이를 분석할 수 있다. ANOVA는 F-test의 일종이다. ANOVA의 종류는 매우 많지만 지금은 일단 가장 기본적인 one way ANOVA에 대해 알아보자. ANOVA 검정 시 F값은 집단 간 분산 / 집단 내 분산으로 계산한다. (전체 평균과 각 집단의 평균을 가지고 만든 분산) / (각 집단의 평균과 개별 값으로 만든 분산)으로 계산한다. <br>\n",
    "ISTP = MBTI.loc[MBTI['mbti'] == 'ISTP', '수명']<br>\n",
    "ESFP = MBTI.loc[MBTI['mbti'] == 'ESFP', '수명']<br>\n",
    "INFP = MBTI.loc[MBTI['mbti'] == 'INFP', '수명']<br>\n",
    "spst.f_oneway(ISTP, ESFP, INFP)<br>\n",
    "결과는 F_onewayResult(statistic=f값,pvalue=p값)\n",
    "주의 : ANOVA는 전체 평균 대비 각 그룹 간 차이가 있는지만 알 수 있다. 즉 모두가 서로 다르다가 아니라, 하나가 튀고 나머지가 비슷하더라도 귀무가설을 기각하는 결과가 나올 수 있다. <br> 이상치를 어떻게 알까? 사후분석을 진행하면 알 수 있다. 다양한 방법이 있지만 튜키의 HSD 테스트를 사용한다. 코드는 다음과 같다.<br>\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd<br>\n",
    "tukey = pairwise_tukeyhsd(endog=MBTI['수명'], groups=MBTI['mbti종류'], alpha=0.05)<br>\n",
    "print(tukey)<br>\n",
    "#### [범주형-범주형] Chi2-test\n",
    "##### 시각화로 알아보는 방법\n",
    "모자이크 플롯 사용한다.<br>\n",
    "from statsmodels.graphics.mosaicplot import mosaic<br>\n",
    "mosaic(df, ['col_행','col_열'])<br>\n",
    "plt.axhline(표시할 값, color = '원하는색')<br>\n",
    "Res : 범주별 차이가 명확하게 보인다. 차이가 명확하게 보이지 않는다면 독립적인 가능성이 큰 것이다. \n",
    "##### 수치화로 알아보는 방법\n",
    "가설<br>\n",
    "H0 : 경영학과 여부와 갈색머리 여부는 관련이 없다.  H1 : 경영학과 여부와 갈색머리 여부는 관련이 있다. <br>\n",
    "경영학과와 갈색머리가 연관이 없다면 -> 기대빈도 get <br>\n",
    "실제로 관측된 값 -> 관측 빈도 get <br>\n",
    "관측빈도와 기대빈도가 서로 차이가 크다면... -> 둘이 독립적이지 않을 가능성이 높다. <br>\n",
    "관측빈도와 기대빈도 사이에 차이가 크다는 것은 해당 범주들이 무작위로 분포하지 않고, 어떠한 패턴을 따르고 있다는 것을 의미한다. 이러한 패턴은 두 변수 간에 종속적인 관계가 있음을 시사하며, 이는 두 변수 사이에 통계적으로 유의미한 연관성이 있을 가능성을 나타낸다. 따라서, 카이제곱 검정에서 큰 차이가 나타나면, 두 변수는 독립적이지 않다고 볼 수 있으며, 이는 대립가설을 지지하는 결과이다. <br>\n",
    "카이제곱 통계량은 다음과 같이 구한다. (관측빈도 - 기대빈도)^2 / 기대빈도 를 쌍만 맞게, 순서 상관 없이 쭉 더해주면 된다. 카이제곱 분석은 범주 갯수에 제한이 없다. 하지만 범주가 많아질수록 통계량이 커질 수 밖에... 그래서 카이제곱 통계량 해석은 어떠한 특정 숫자가 아닌, 자유도의 약 2배 가량을 기준으로 잡는다. 범주형 변수이 자유도는 범주의 수 - 1이 되는데 카이제곱 변수의 자유도는 (x변수의 자유도)*(y변수의 자유도)로 계산한다. 코드는 다음과 같이 작성하면 된다.<br>\n",
    "table = pd.crosstab(df['col1'], df['col2'])<br>\n",
    "spst.chi2_contingency(table)<br>\n",
    "결과값은 (카이제곱 통계량, p값, 자유도, 기대빈도)가 된다. <br>\n",
    "But 샘플의 크기가 작을때는 fisher_exact test를 사용하는 것이 옳다. 이는 정확한 p값을 제공해준다. <br>\n",
    "from scipy.stats import fisher_exact<br>\n",
    "table = pd.crosstab(df['col1'], df['col2'])<br>\n",
    "fisher_exact(table)<br>\n",
    "#### [수치형-범주형]\n",
    "##### 시각화로 알아보는 방법\n",
    "sns.kdeplot으로 수치형이 변화할때 범주형의 비율이 어떻게 변화하는지를 알 수 있다. \n",
    "sns.kdeplot(x = 'col_수치', data = df, hue = 'col_범주')\n",
    "##### 수치화로 알아보는 방법\n",
    "아직은 때가 아님... ㅎ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ea668-6dfd-4b20-bf50-731c792fb391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
