{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5497c095-f962-4e4b-a0c1-a634a02f0db4",
   "metadata": {},
   "source": [
    "## 데이터 분석 프로세스\n",
    "데이터 수집 : 다양한 데이터 수집\n",
    "데이터 탐색 : 수집한 데이터를 여러 방식으로 파악 <- EDA\n",
    "데이터 전처리 : 모델링을 위해 데이터를 적절한 방식으로 조작\n",
    "데이터 모델링 : 유용한 정보를 추출하기 위해 모델 구축하기\n",
    "goal : 탐색 ~ 전처리 단계 학습\n",
    "\n",
    "## 1. EDA 개념\n",
    "데이터를 여러 가지 방식으로 파악하는 모든 과정 : 패턴 발견, 특이성 발견, 시각적 표현으로 가설을 검정\n",
    "EDA : Exploratory Data Analysis, 탐색적 데이터 분석 과정\n",
    "#### EDA 대상 (1변량, 多변량)\n",
    "- 일변량 : 변수 1개로 데이터를 설명 & 존재하는 패턴 찾기\n",
    "- 다변량 : 변수 여러 개, 관계 파악이 목적, 개별 데이터 파악이 우선시 되어야\n",
    "#### EDA 종류 (시각화, 비시각화)\n",
    "- 시각화 : 시각적 이미지(표, 그림, 그래프 등)\n",
    "- 비시각화 : 수치적 자료, 통계적 자료\n",
    "#### EDA 유형\n",
    "대상과 종류에 따라 구분된다. { 일변량 시각화, 일변량 비시각화, 다변량 시각화, 다변량 비시각화 }\n",
    "\n",
    "## 2. 데이터 확인\n",
    "### 데이터 읽기 기기\n",
    "- 읽기 : 작업 공간에 데이터 불러오기\n",
    "- 쓰기 : 데이터를 만드는 것\n",
    "#### 절대경로, 상대경로\n",
    "- 절대경로 : root부터 dst까지의 전체 경로\n",
    "- 상대경로 : 현재 위치를 기준으로 상대적으로 표현\n",
    "#### 데이터 입출력\n",
    "파일 형식에 따라 reader, writer가 다름\n",
    "#### CSV, EXCEL\n",
    "- CSV : comma serparated value, 쉼표로 데이터 구분  ex_code } pd.read_csv(\"path.csv\")\n",
    "- EXCEL : 데이터 프레임과 일대일 대응\n",
    "      ex_code } sheet_name = 'Sheet 2', sheet_name = ['Sheet 1', 'Sheet 2'], pd.read_excel('파일경로(이름).xlsx, sheet_name = '불러올 시트')\n",
    "### 데이터셋 파악하기\n",
    "1. 데이터 프레임 보기\n",
    "2. 데이터 변수 확인\n",
    "   1) 변수 정의 확인\n",
    "   2) 변수 유형 확인 : 질적:범주형, 양적:수치형으로 구분한다. 양적:수치형 데이터 중 트렌드가 보이면 연속형, 트렌드가 없다면 이산형으로 구분\n",
    "          범주형 : 몇 개의 범주로 나누어진 데이터\n",
    "              명목형 : 성별, 성공여부, 혈액형 등 순서 없이 단순히 분류된 자료\n",
    "              순서형 : 범주형 데이터 중 그들 사이에 순서 관계가 존재하는 자료\n",
    "          수치형 : 숫자로 표현되는 데이터\n",
    "              이산형 : 이산적인 값으로, 정수 단위로 떨어져 셀 수 있는 데이터\n",
    "              연속형 : 연속적인 값을 갖는 데이터로 신장, 체중 등\n",
    "3. 데이터 분포 확인\n",
    "   단변수 분석은 하나의 데이터 분포를 확인해 분석할 수 있는 방법. 이를 통해 전처리의 아이디어를 얻을 수 있게 된다.\n",
    "\n",
    "## 3. 전처리\n",
    "모델링을 위해 데이터를 적절한 방식으로 조작, 손질\n",
    "과정은 다음과 같다. \n",
    "1. 데이터 확인 2. 결측값 처리 3. 이상값 처리 4. 변수 가공 5. 데이터 통합\n",
    "- 데이터 확인\n",
    "  데이터의 구조, 크기, 특성 등을 파악하는 첫 단계. 데이터가 올바르게 입력되었는지, 누락된 값이나 이상값이 있는지를 확인, 데이터 정제와 관련 있다.\n",
    "- 결측값 처리\n",
    "  누락된 데이터를 보완하거나 제거. 데이터 정제의 중요한 단계로 누락된 값을 처리함으로써 데이ㅌ의 신뢰성을 높여주며, 데이터의 일관성을 유지하게 해준다.\n",
    "- 이상값 처리\n",
    "  정상적인 범위를 벗어난 튀는 값(이상값)을 식별하고 처리하는 단계. 데이터 필터링과 관련 있으며, 이상값을 필터링하여 분석에 적합한 데이터만을 남기고 오류가 있는 값을 제거하는 작업.\n",
    "- 변수 가공\n",
    "  데이터를 분석 목적에 맞게 변환한다. 데이터 변환과 밀접하게 관련이 있다. 분석에 용이하도록 변수를 생성하거나 데이터 형식을 변환하며 이를 통해 중복된 데이터를 줄이고 일관성을 확보할 수 있다.\n",
    "- 데이터 통합\n",
    "  여러 소스에서 가져온 데이터를 통합하는 과정이다. 데이터베이스에서 추출한 정보나 다른 시스템에서 가져온 데이터를 하나로 합쳐 분석할 수 있는 데이터로 만드는 것이 핵심\n",
    "### 결측값 처리\n",
    "결측값 : 데이터 수집 과정에서 측정되지 않거나 누락된 데이터\n",
    "결측값이 있는 상태로 모델을 만들면 변수 간 왜곡으로 인해 정확성이 떨어지고 시각화에 문제가 발생할 수도.. \n",
    "#### <1> 결측값 확인\n",
    "NaN, ?, 0 등의 값을 확인한다. 유용한 함수로는...\n",
    "info(), values_counts(), isnull(), notnull(), replace()\n",
    "#### <2> 결측값 처리\n",
    "1) 삭제 :: dropna{drop not available} : 결측값이 포함된 레이블을 제거한다. ex_code } DataFrame.dropna(axis=0/1, how='any'/'all',subset=[col1,col2,...],inplace='True','False'\n",
    "2) 대체 :: fillna{fill not available}\n",
    "   ex_code_1 } 일괄 대체\n",
    "   a = df[\"열1\"].mean(axis=0)\n",
    "   df[\"열1\"].fillna(a,inplace=True)\n",
    "   ex_code_2 } 유사 유형 대체\n",
    "   category_means = df.groupby('Category')['Value'].mean()\n",
    "   df['Value'] = df.groupby('Category')['Value'].apply(lambda x: x.fillna(x.mean()))\n",
    "### 이상치 처리\n",
    "이상치 : 관측된 데이터의 범위에서 많이 벗어난 값\n",
    "이상치를 처리해주지 않으면 데이터 분석에 큰 영향을 끼친다.\n",
    "#### <1> 이상치 확인\n",
    "1) 통계를 통해 확인 : describe()\n",
    "2) 시각화를 통해 확인 : BoxPlot\n",
    "3) Z-Score를 통해 확인 : 해당 데이터가 평균으로부터 얼마의 표준편차만큼 벗어나 있는지를 확인\n",
    "       Z < 0 -> 평균 이하\n",
    "       Z >= 0 -> 평균 이상\n",
    "4) 튜키 펜스를 통해 확인 : 사분위 범위를 기반으로 2가지 경우에 이상치라고 판단\n",
    "       이상치를 Outliers라고 한다. Outliers : 밖에 있는 것\n",
    "#### <2> 이상치 제거\n",
    "1) 전체 삭제 : 이상값이 인간적인 오류로 발생했을때. 오타, 너무 비현실적 응답, 데이터 처리에서의 오류\n",
    "2) 다른 값을 대체 : 관측치(표본)의 숫자가 작은 경우, 삭제를 통해 이상치를 제거하면... 관측치의 절대량이 작아져 신뢰성 문제가 발생.\n",
    "3) 변수화 : 이상값이 자연 발생한 경우, 단순 삭제나 대체의 방법을 통해 수립된 모델은 설명/예측하고자하는 현상을 잘 설명하지 못할 수도 있다. 이 경우, 바로 삭제하지 말고 이상값에 대해서 천천히 차근차근 파악해보는 것이 중요하다.\n",
    "4) 리샘플링 : 이상값을 분리해서 모델을 만드는 방법이 있다. 강의자료의 예시에서 설명변수와 종속변수 모두에 대해서 outlier이므로... 이상값을 제외하는 방법 말고 이상값을 포함한 모델 미포함한 모델을 모두 만들고 각각의 모델에 대한 설명을 다는 것이 중요하다.\n",
    "   \n",
    "ex_code } 튜키 펜스를 이용한 이상치 확인 및 제거 예시\n",
    "def find_outlier_by_Tukey_DF(data, feature): // 주어진 데이터에서 튜키 펜스를 사용하여 이상치를 찾는 함수\n",
    "    q1, q3 = np.percentile(data[feature],[25,75])\n",
    "    iqr = q3-q1\n",
    "    \n",
    "    lower_bound = q1 - (iqr * 1.5)\n",
    "    upper_bound = q3 + (iqr * 1.5)\n",
    "    print(f'lower_bound는 {lower_bound.round(3)}, upper_bound는 {upper_bound.round(3)} 입니다')\n",
    "    \n",
    "    mask = data[(data[feature] > upper_bound) | (data[feature] < lower_bound)].index  // 상한 또는 하한을 벗어난 이상치의 인덱스를 찾는다.\n",
    "    return mask.     \n",
    "\n",
    "mask = find_outlier_by_Tukey_DF(df, 'BMI') // BMI 열에서 이상치를 찾는다.\n",
    "print(f'해당 열의 이상치는 {len(mask)}개 입니다')\n",
    "\n",
    "for i in range(len(mask)):  // 찾은 이상치를 DF에서 제\n",
    "    df = df.drop(index=mask[i])\n",
    "df = df.reset_index(drop=True)\n",
    "### 피처 엔지니어링 (변수 가공)\n",
    "컴퓨터가 문제를 잘 이해할 수 있도록 변수(피처)들의 형태를 변형 혹은 적절히 처리하는 과정\n",
    "데이터 전처리의 마지막 단계로 새로운 데이터 또는 변수의 추가 없이 기존의 데이터를 보다 유용하게 만드는 방법이며, 도메인 지식 여부에 따라 변수 가공의 결과와 그 유의성이 많이 달라지기도 한다. \n",
    "#### 방식\n",
    "1. 레이블 인코딩, 원 핫 인코딩\n",
    "   - 레이블 인코딩 : 범주형 변수를 0 ~ N - 1까지의 숫자로 변환한다.\n",
    "   - 원 핫 인코딩 : 범주형 변수를 이진 벡터로 변환한다. 범주 간 순서가 없는 경우 사용된다. ex) 카테고리형 데이터가 순서가 없고, 각 값이 독립적이라면 이 방법이 적합하다.\n",
    "2. 구간화 : 연속 데이터를 일정한 구간으로 나누어 분석.\n",
    "   ex_code } pd.cut(DF['col_name'],bins=[나누는 기준 리스트],labels = [지정할 label])\n",
    "3. 변환\n",
    "   기존의 피처를 다른 피처로 변환하여 변수를 추가한다.\n",
    "4. 스케일링\n",
    "   서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업. 데이터 정규화 과정 실행. 2가지 방법이 있다.\n",
    "    1) StadardScaler (표준화)\n",
    "    2) MinMaxScaler (0~1 사이의 값으로)\n",
    "   각각 정규화하는 함수가 sklearn.preprocessing 모듈에 있음.\n",
    "\n",
    "## 4. 시각화\n",
    "시각화는 데이터나 정보를 시각적인 형태로 표현하는 과정 또는 결과물을 말한다. \n",
    "데이터 -> 시각적 요소 : 패턴, 관계, 추세 파악 용이\n",
    "시각화를 어떻게..?\n",
    "Matplotlib, Seaborn 라이브러리를 활용한다. \n",
    "시각화를 하기 전 데이터가 범주형인지 수치형인지 파악, 결측값 및 이상치가 있는지를 확인한다. 데이터의 특성 파악 후 특성에 적합한 그래프를 사용.\n",
    "#### 파라미터\n",
    "매개변수(파라미터) : 함수의 입력 값\n",
    "### 다양한 그래프들\n",
    "1. Boxplot : 사분위수와 이상치를 표현 (상자수염그림)\n",
    "2. countplot, histplot\n",
    "   countplot : 범주형 변수의 빈도 수\n",
    "   histplot : 도수분포표, 수치형 변수의 구간별 빈도수를 나타낸다.\n",
    "3. displot, kdeplot : 히스토그램을 연속적으로 곡선으로 연결한 그래프 (커널밀도추정 그래프)\n",
    "4. barplot, pointplot : 범주형 데이터 값 x에 따른 수치형 데이터 값 y의 평균 값을 제공. pointplot은 막대 그래프와 모양만 다르고 동일 정보 제공(점,선 이용)\n",
    "5. scatterplot(산점도 그래프), regplot(회귀선 추가 그래프) : 두 변수 간의 관계를 나타낸다.\n",
    "6. catplot(카테고리 플롯) : 수치형 데이터와 범주형 데이터 간의 관계를 볼 때 사용\n",
    "7. pieplot : 데이터의 부분과 전체 간 비율을 표현하는 그래프\n",
    "8. heatmap : 변수간 상관계수를 볼 수 있는 그래프. 즉, 서로 영향을 주는 정도를 나타내는 값이다.\n",
    "9. violinplot : 박스 플롯과 커널밀도 추정 함수 그래프를 합쳐 놓은 그래프\n",
    "10. pairplot : 여러 변수 간의 산점도를 한번에 보여주는 그래프"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
