{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb2dd4ed-d7d4-4a1b-87ef-f8c82ee6f7b6",
   "metadata": {},
   "source": [
    "- **[ 지도학습과 비지도학습 ]**\n",
    "    \n",
    "    차이점 : 지도 학습은 정답이 주어진 상태에서 학습하는 알고리즘을 의미하고 비지도 학습은 정답이 주어지지 않은 상태에서 학습하는 알고리즘이다. \n",
    "    \n",
    "    [ 머신러닝이란? ]\n",
    "    \n",
    "    인공지능의 한 분야로, 컴퓨터가 스스로 학습할 수 있게 도와주는 알고리즘\n",
    "    \n",
    "    1. 알고리즘을 사용하여 데이터를 분석한다.\n",
    "    2. 분석 결과를 스스로 학습한다.\n",
    "    3. 결과를 바탕으로 어떤 판단이나 예측을 한다 .\n",
    "    \n",
    "    [ 지도 학습 ]\n",
    "    \n",
    "    정답이 있는 데이터를 사용하여 공부시킨다.\n",
    "    \n",
    "    예측값을 이미 만들어둔 정답과 같아지도록 기계를 학습시키는 것으로 회귀와 분류가 지도학습에 속한다. \n",
    "    \n",
    "    [ 비지도 학습 ]\n",
    "    \n",
    "    비지도 학습은 정답이 없는 데이터를 사용한다. 데이터 속의 패턴 또는 데이터 간의 유사도를 기계가 학습하도록 한다. 비지도 학습의 예시로 군집화, 밀도 추정, 차원 축소 등이 있다. \n",
    "    \n",
    "- **[ 회귀와 분류의 차이 ]**\n",
    "    \n",
    "    둘 다 지도학습의 일환이므로 우선 지도학습에 대해 다시 복습하자. \n",
    "    \n",
    "    [ 지도 학습 ]\n",
    "    \n",
    "    지도 학습은 입력값과 함께 결과 값(정답 레이블)을 같이 주고 학습을 시키는 방법이다. 학습의 방향은 예측값과 정답이 최대한 같아지도록 학습시킨다. \n",
    "    \n",
    "    입력 데이터와 그에 대응하는 출력값이 있는 데이터인 레이블 데이터를 training set와 test set으로 나눈다. 그 후, training set을 통해 모델을 학습시킨다. 이 과정은 독립변수를 통해 추정한 예측값이 주어진 종속 변수와 같아지도록 모델을 훈련시키는 과정이다. \n",
    "    \n",
    "    [ 회귀와 분류 ]\n",
    "    \n",
    "    회귀 : 연속적인 숫자값을 예측한다. 주어진 X를 기반으로 정답 Y를 잘 맞추는(fit)하는 함수\n",
    "    \n",
    "    분류 : 기존 데이터가 어떤 레이블에 속하는지 패턴을 알고리즘으로 인지한 뒤에 새롭게 관측된 데이터에 대한 레이블을 판별하는 것.\n",
    "    \n",
    "    회귀와 분류의 차이는 예측하는 값의 종류에 따라 나뉘게 된다.\n",
    "    \n",
    "    회귀는 연속적인 변수를 예측하기 위해 사용되고 \n",
    "    \n",
    "    분류는 종속적인 변수를 예측하기 위해 사용된다.\n",
    "    \n",
    "    [ 이진 분류와 다중 분류 ]\n",
    "    \n",
    "    이진 분류는 예측하고자 하는 변수 어떤 기준에 대하여 참 또는 거짓의 값만을 가진다. \n",
    "    \n",
    "    다중 분류는 예측하고자 하는 변수가 가질 수 있는 값이 3개 이상이다. \n",
    "    \n",
    "- **[ 분류 모델의 4가지 종류와 각 모델에 대한 정리 ]**\n",
    "    1. **로지스틱 회귀**\n",
    "        - contents\n",
    "            \n",
    "            이진 분류 문제를 푸는 대표적인 알고리즘으로 샘플이 특정 클래스에 속할 확률을 추정하는 것을 목표로 한다. 다시 말해, 로지스틱 회귀란, 독립 변수의 선형 회귀에 로지스틱 함수를 적용하여 출력값을 0에서 1 사이로 변환해주는 것을 의미한다 . 0에서 1 사이로 변환한다는 특징 때문에 로지스틱 회귀는 이진 분류 문제를 해결하는데 적합하다. \n",
    "            \n",
    "            시그모이드 함수 = 로지스틱 함수 : 출력이 0과 1 사이의 값을 가지면서 S자 형태로 그려지는 함수. \n",
    "            \n",
    "            - code\n",
    "                \n",
    "                ```python\n",
    "                def sigmoid(x):\n",
    "                \treturn 1/(1+np.exp(-x))\n",
    "                \t\n",
    "                x = np.arange(-5.0,5.0,0.1)\n",
    "                y = sigmoid(x)\n",
    "                \n",
    "                plt.plot(x,y,'g')\n",
    "                plt.plot([0,0],[1.0,0.0],':')  # 가운데 점선 추가\n",
    "                plt.title('Sigmoid Function')\n",
    "                plt.show()\n",
    "                ```\n",
    "                \n",
    "            \n",
    "            시그모이드 함수 가중치 : 인공지능이 하는 것은 결국 주어진 데이터에 적합한 가중치 w, b를 구하는 것이다. \n",
    "            \n",
    "            < w에 따른 그래프의 변화 > \n",
    "            \n",
    "            ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ee620b36-4663-419f-bd1c-683a8774e63e/c8681f9d-9f8c-47c8-ad89-1e2135b895c9/image.png)\n",
    "            \n",
    "            - code\n",
    "                \n",
    "                ```python\n",
    "                def sigmoid(x):\n",
    "                    return 1/(1+np.exp(-x))\n",
    "                \n",
    "                x = np.arange(-5.0, 5.0, 0.1)\n",
    "                y1 = sigmoid(0.5*x)\n",
    "                y2 = sigmoid(x)\n",
    "                y3 = sigmoid(2*x)\n",
    "                \n",
    "                plt.plot(x, y1, 'r', linestyle='--') # w의 값이 0.5일때\n",
    "                plt.plot(x, y2, 'g') # w의 값이 1일때\n",
    "                plt.plot(x, y3, 'b', linestyle='--') # w의 값이 2일때\n",
    "                plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n",
    "                plt.title('Sigmoid Function')\n",
    "                plt.show()\n",
    "                ```\n",
    "                \n",
    "            \n",
    "            < b에 따른 가중치의 변화 >\n",
    "            \n",
    "            ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ee620b36-4663-419f-bd1c-683a8774e63e/8d2a2dfd-d6a8-4039-a47b-8e427afa65cb/image.png)\n",
    "            \n",
    "            - code\n",
    "                \n",
    "                ```python\n",
    "                def sigmoid(x):\n",
    "                    return 1/(1+np.exp(-x))\n",
    "                \n",
    "                x = np.arange(-5.0, 5.0, 0.1)\n",
    "                y1 = sigmoid(x+0.5)\n",
    "                y2 = sigmoid(x+1)\n",
    "                y3 = sigmoid(x+1.5)\n",
    "                \n",
    "                plt.plot(x, y1, 'r', linestyle='--') # x + 0.5\n",
    "                plt.plot(x, y2, 'g') # x + 1\n",
    "                plt.plot(x, y3, 'b', linestyle='--') # x + 1.5\n",
    "                plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n",
    "                plt.title('Sigmoid Function')\n",
    "                plt.show()\n",
    "                ```\n",
    "                \n",
    "    2. **결정 나무** \n",
    "        - contents\n",
    "            \n",
    "            결정 나무란 조건에 따라 데이터를 분류하며, 최종적으로 데이터가 순수한 label의 집합으로 구성될 때까지 분류를 계속 반복하는 모델\n",
    "            \n",
    "            [ CART 알고리즘 ]\n",
    "            \n",
    "            CART : 데이터셋을 임계값을 기준으로 두 child로 나누는 알고리즘 \n",
    "            \n",
    "            임계값을 어떻게 나눠야 하나요 ? 불순도가 낮아지는 방향으로\n",
    "            \n",
    "            불순도란 분류하려는 데이터 집합에서 서로 다른 클래스가 섞여 있는 정도를 의미한다. CART 알고리즘에서는 불순도를 확인하기 위해 지니 계수를 사용한다. \n",
    "            \n",
    "            - 지니 계수란 ?\n",
    "                \n",
    "                ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ee620b36-4663-419f-bd1c-683a8774e63e/f20cee21-ec25-47f4-aa06-7ca31a713d84/image.png)\n",
    "                \n",
    "                지니계수는 불순도를 나타내며 통계적 분산 정도를 정량화해서 표현한 값이다. \n",
    "                \n",
    "                이를 통해 얼마나 불확실한지 (얼마나 많은 것이 섞여 있는지) 알 수 있다. \n",
    "                \n",
    "            \n",
    "            < 알고리즘 단계 >\n",
    "            \n",
    "            1. 임계값 설정 \n",
    "            2. 불순도 가소 알고리즘 \n",
    "            \n",
    "            [ 실제 학습시 고려해야 하는 것들 ]\n",
    "            \n",
    "            1. Parameter 설정\n",
    "            2. 시각화 \n",
    "            3. Prunning (가지치기)\n",
    "    3. **SVM ( 서포트 벡터 머신 )**\n",
    "        - contents\n",
    "            \n",
    "            서포트 벡터 머신 : 클래스를 분류할 수 있는 다양한 경계선 중 최적의 라인을 찾아내는 알고리즘. → 명확하게 분류할 수 있는 데이터 집단에서 뛰어난 성능을 보이며, 고차원 공간에서도 효과적으로 사용 가능하다. \n",
    "            \n",
    "            [ SVM의 구성 ]\n",
    "            \n",
    "            1. support vector : 구분선과 가장 가까운 point\n",
    "            2. decision boundary : 집단을 구분하는 선\n",
    "            3. margin : 선과 각 점의 거리\n",
    "            \n",
    "            [ 최적의 선을 찾는 방법 ]\n",
    "            \n",
    "            결정 경계는 데이터로부터 가장 멀리 떨어져 있는게 좋다. 따라서 SVM은 Margin (거리)가 가장 큰 경우를 선택함으로써 최적의 선을 찾는다 . \n",
    "            \n",
    "    4. KNN (K-Nearest Neighbor)\n",
    "        - contents\n",
    "            \n",
    "            KNN : 거리가 가까운 k개의 다른 데이터 레이블을 참조하여 분류하는 알고리즘\n",
    "            \n",
    "            [ 알고리즘 단계 ]\n",
    "            \n",
    "            1. 데이터 준비\n",
    "            2. K값 설정\n",
    "            3. 거리 계산\n",
    "            4. 가장 가까운 K개의 이웃 선택\n",
    "            5. 분류하기\n",
    "            \n",
    "            KNN은 어떠한 학습이 필요하지 않다. 별도의 모델없이 데이터만을 이용해서 새로운 데이터가 왔을 때, 그때 즉석에서 주변 데이터들을 이용하여 classify를 하는 것이다. \n",
    "            \n",
    "- **[ 분류 평가 지표 ]**\n",
    "    1. 혼동 행렬\n",
    "        - contents\n",
    "            \n",
    "            혼동 행렬이란 분류 모델의 예측 결과를 정확한 예측과 잘못된 예측으로 구분하여 나타낸 표이다 \n",
    "            \n",
    "            ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ee620b36-4663-419f-bd1c-683a8774e63e/3c4f6973-c940-42ba-a9cf-dc855fece439/image.png)\n",
    "            \n",
    "            예측 성공 여부(T/F) + 예측 값(P/N)으로 구분하여 총 4가지 경우가 있다.\n",
    "            \n",
    "            1. TP : 예측 성공, 예측값 Positive\n",
    "            2. TN : 예측 성공, 예측값 Negative\n",
    "            3. FN : 예측 실패, 예측값 Negative\n",
    "            4. FP : 예측 실패, 예측값 Positive\n",
    "            \n",
    "            < 혼동 행렬을 이용한 분류 모델 평가 지표 >\n",
    "            \n",
    "            1. Accuracy(정확도) : 모든 예측 중 성공한 예측의 비율 (TP+TN)/(ALL)\n",
    "            2. Precision(정밀도) : 예측 ‘참’ 중 실제 ‘참’ TP / (TP+FP). 거짓을 참이라고 한 비율을 알 수 있다. \n",
    "            3. Recall(재현도) : 실제 ‘참’ 중 예측 ‘참’의 비율 TP / (TP+FN)\n",
    "            \n",
    "            < Precision과 Recall의 관계 : Trade-Off 관계 >\n",
    "            \n",
    "            분류를 할 때, 확률에 기반해서 Threshold가 넘으면 True, Threshold 미만이면 거짓으로 판단한다. Threshold를 조정해서 Precision과 Recall을 조정할 수 있다. \n",
    "            \n",
    "            < Threshold 설정 > \n",
    "            \n",
    "            정밀도, 재현도 그래프에서 두 value가 만나는 지점을 Threshold로 정하면 예측 오류를 최소화할 수 있다. \n",
    "            \n",
    "    2. F1-Score : Precision과 Recall의 조화 평균\n",
    "    3. ROC/AUC Curve\n",
    "        - contents\n",
    "            \n",
    "            ROC Curve: 얼마나 분류가 잘 되었는가를 보여주는 그래프\n",
    "            \n",
    "            ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ee620b36-4663-419f-bd1c-683a8774e63e/aa18bf5b-15d9-44b3-8f21-43a6753b5771/image.png)\n",
    "            \n",
    "            → 완벽한 분류기는 나올 수가 없다. 따라서 현실적인 한계를 고려하여 적절히 타협한 최선의 ROC Curve를 도출해야 한다. \n",
    "            \n",
    "            AUC curve : ROC와 x축 사이의 면적\n",
    "            \n",
    "            ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ee620b36-4663-419f-bd1c-683a8774e63e/03e6c918-21b9-41c9-b3bb-058ca0a7f5f8/image.png)\n",
    "            \n",
    "            → 모델의 성능을 숫자로 나타낼 수 있다. 0~1 사이의 값을 가지며, 1에 가까울 수록 분류 성능이 좋은 것에 해당한다. \n",
    "            \n",
    "- **[ 하이퍼파라미터 최적화 ]**\n",
    "    \n",
    "    하이퍼파라미터 : 학습 시작 전 사용자가 직접 설정하는 변수\n",
    "    \n",
    "    하이퍼파라미터 최적화 : 적절한 하이퍼파라미터를 찾아 모델 성능을 향상시키는 것\n",
    "    \n",
    "    < 최적화 방법 > \n",
    "    \n",
    "    1. Grid Search : 정해진 범위에서 Hyperparameter를 모두 순회\n",
    "    2. Random Search : 정해진 범위에서 Hyperparameter를 무작위로 탐색\n",
    "    3. Bayesian Optimization : 사전 정보를 바탕으로 하이퍼파라미터 값을 확률적으로 추정하며 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43f0a1-a7d2-47fc-b749-a498ee958088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
