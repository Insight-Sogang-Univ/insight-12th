{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d39c5b7-80b9-4b06-8977-d978140072dd",
   "metadata": {},
   "source": [
    "# 회귀 심화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b206e18-8b96-4888-ab4c-a190ae98e274",
   "metadata": {},
   "source": [
    "* 회귀?\n",
    "\n",
    "  연속적인 데이터에서 패턴(함수관계)을 찾아내는 통계적 방법\n",
    "\n",
    "  cf) 지도학습 : 정답으로 간주할 데이터가 있음 <- 회귀!\n",
    "\n",
    "  비지도학습 : 정답으로 간주할 데이터가 없음 \n",
    "\n",
    "  -> 회귀는 데이터 분석의 유용한 도구이자, ML/DL 이해의 밑바탕!\n",
    "\n",
    "\n",
    "* 단순선형회귀분석\n",
    "\n",
    "* 다중선형회귀분석\n",
    "\n",
    "  -> 설명변수 개수의 차이일 뿐!\n",
    "\n",
    "* 최소자승법(OLS)\n",
    "\n",
    "  잔차 제곱 합을 최소화하는 회귀선을 찾는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3f7c1-1342-4fdf-8ce0-3a00e7dcd074",
   "metadata": {},
   "source": [
    "1. 선형회귀\n",
    "\n",
    "   선형회귀식은 종속변수 y에 대한 설명변수의 가중평균\n",
    "\n",
    "   BUT! 선형회귀를 모든 상황에 사용할 수 있는 것은 아니다!\n",
    "  \n",
    " - 다중선형회귀의 기본 가정\n",
    "\n",
    "   a. 선형성 : 종속변수와 설명변수 간 관계가 선형적이어야 함\n",
    "\n",
    "   b. 오차항의 평균은 0 : 백색 잡음이라고도 하는 오차항, 백색 잡음의 성질을 만족하기 위해 가정!\n",
    "\n",
    "   c. 독립성 : 각각의 설명변수가 서로 선형독립적이어야 함 (다중공선성을 배제해야 함 by VIF, PCA)\n",
    "\n",
    "   d. 등분산성 : 오차항의 분산이 일정해야 함 (횡단면 자료에 이분산 多)\n",
    "\n",
    "   등분산성을 알아보는 방법? 1. 잔차의 도표화 2. 검정\n",
    "\n",
    "   e. 오차항은 자기상관되어있지 않음 : 오차항의 공분산은 0이어야 함 (시계열 자료에 자기상관 多)\n",
    "\n",
    "   자기상관을 알아보는 방법? 1. 더빈-왓슨 검정 2. ACF, PACF함수 찍어보기\n",
    "\n",
    "   f. 정규성 : 오차항이 정규분포를 따른다는 가정, 이는 위배되어도 결과에 큰 영향을 끼치지 않음\n",
    "\n",
    "   정규성을 알아보는 방법? 1. 샤피로-윌크 검정 2. 자퀴-베라 검정 3. Q-Q plot 찍어보기\n",
    "\n",
    " -  회귀분석 평가방법\n",
    "\n",
    "   a. 시각화\n",
    "\n",
    "   두 집단의 차이를 객관적으로 비교하기 위해 통계지표를 활용하는 것이 좋음.\n",
    "\n",
    "   b. 통계지표\n",
    "\n",
    "   회귀분석의 결과를 평가하는 가장 대표적인 지표인 결정계수(R-squared)와 이를 보완한 지표 有\n",
    "\n",
    "       - 결정계수(R^2) : 회귀분석에서 모델이 설명하는 데이터의 총 변동 중 설명된 비율 / 모델이 데이터를 얼마나 잘 설명하는지 측정하는 지표 / 0과 1 사이의 값으로 나타남 / 1에 가까울수록 모델이 데이터를 잘 설명한다!\n",
    "\n",
    "       - 조정된 결정계수 (Adjusted R^2) : 결정계수는 설명변수의 개수가 증가할수록 자연스레 증가 -> 데이터에 큰 관련성이 없는 변수를 추가해도 결정계수는 높아짐  -> 변수의 개수 증가에 덜 민감하도록 조정한 지표가 조정된 결정계수! / 결정계수에 ((n-1)/(n-k))를 곱함\n",
    "\n",
    "       - AIC, BIC(SC) : 두 지표 모두 정보기준이라고도 불림, 값이 낮을수록 좋다고 평가 / AIC는 BIC에 비해 복잡성에 대한 패널티가 비교적 작음 / BIC는 AIC보다 엄격한 기준으로 데이터의 양에 따라 더 강한 패널티 부과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea6cff6-3d5d-434b-a8ee-4cc526ddecdf",
   "metadata": {},
   "source": [
    "2. 비선형회귀\n",
    "\n",
    "   데이터셋의 분포가 선형적이지 않을 가능성 有\n",
    "\n",
    "   -> 회귀는 데이터 간 패턴(함수관계)를 나타내는 것이므로, 선형적이지 않은 식을 작성하면 됨!\n",
    "\n",
    "   a. 다항식 회귀모델\n",
    "\n",
    "    선형 모델의 feature를 다향식으로 만들어 선형회귀 사용\n",
    "\n",
    "   사이킷런 라이브러리의 PolynomialFeatures() 메서드를 사용하여 기존의 변수를 2차항화하고 선형회귀를 사용\n",
    "\n",
    "   선형모델에 비해 회귀선을 잘 fit하도록 그릴 수 있지만, 너무 많은 feature를 이용하면 결과가 overfitting될 수도 있음 -> overfitting을 방지하기 위해 릿지, 라쏘 규제를 이용할 수 있음\n",
    "\n",
    "   b. 지수/로그 회귀모델\n",
    "\n",
    "   어떤 칼럼의 증감 형태가 지수적, 혹은 그 역인 경우 존재 -> 지수/로그 식 활용!\n",
    "\n",
    "   기존식에 지수/로그를 사용해 변형시킨 후 선형회귀 사용input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
