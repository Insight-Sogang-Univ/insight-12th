{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8598c2df-2071-469e-9d34-c773d40a95a3",
   "metadata": {},
   "source": [
    "1. 머신러닝\n",
    "\n",
    "새로운 데이터를 예측하거나 결정을 내릴 수 있도록 하는 기술\n",
    "\n",
    "-> 머신러닝을 통해 데이터에서 패턴을 찾아내고 이 패턴을 바탕으로 새로운 데이터에 대한 예측\n",
    "\n",
    "비지도학습 : 정답이 없는 데이터로 학습하는 방식\n",
    "\n",
    "지도학습 : 정답이 있는 데이터로 학습하는 방식\n",
    "\n",
    "2. 모델링\n",
    "\n",
    "전체 데이터 -> 훈련 데이터 / 테스트 데이터 로 분리 -> 훈련 데이터로 모델 구축 -> 테스트 데이터로 성능 평가 -> 최종 모델 생성\n",
    "\n",
    "훈련 데이터 : 모델을 학습시킬 때 쓰는 데이터\n",
    "\n",
    "테스트 데이터 : 학습된 모델을 검증하기 위해 사용하는 데이터\n",
    "\n",
    "전체 데이터를 쪼개는 이유? 훈련 데이터를 통해 학습시킨 모델이 새로운 데이터에 대해 얼마나 잘 예측을 수행하는지 공정하게 평가하기 위해!\n",
    "\n",
    "cf) 만약 분리하지 않는다면? 훈련시킨 데이터를 그대로 모델 평가에 사용한다면 모델이 뱉은 결과가 단순히 해당 데이터를 암기할 결과일 수 있기 때문에 실제 성능을 평가할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ecc16f-7553-4cf7-aee7-9820dd70f733",
   "metadata": {},
   "source": [
    "3. 회귀\n",
    "\n",
    "회귀는 데이터에서 패턴을 찾아내어 미래 값을 예측하는 것\n",
    "\n",
    "통계 / 머신러닝의 주요 개념\n",
    "\n",
    "집값 예측, 주식 가격 예측 등 연속 숫자를 다룸\n",
    "\n",
    "EX) 선형회귀, 비선형회귀, 로지스틱 회귀, 릿지회귀, 라쏘회귀, 다항회귀 등\n",
    "\n",
    "* 선형회귀?\n",
    "\n",
    " 데이터를 가장 잘 설명하는 회귀선을 찾아 예측하는 과정\n",
    "\n",
    " 종속변수 (예측하고자 하는 것) / 독립변수 (예측을 위해 사용하는 것)\n",
    "\n",
    " 단순 선형 회귀 : 데이터를 하나의 독립 변수로 표현하는 경우\n",
    "\n",
    " 다중 선형 회귀 : 데이터를 두 개 이상의 독립 변수를 사용하여 표현하는 경우\n",
    "\n",
    " cf) 선형 회귀의 기본 가정\n",
    "\n",
    " 선형 회귀 기법을 사용할 수 있는 조건!\n",
    "\n",
    " a. 선형성 : 종속 변수와 독립 변수들 간 관계가 선형적이어야 함\n",
    "\n",
    " b. 독립성 : 각각의 관측치는 서로 독립적이어야 함\n",
    "\n",
    " c. 등분산성 : 모든 독립 변수들의 수준에서 오차항의 분산이 일정해야 함\n",
    "\n",
    " d. 정규성 : 오차항이 정규분포를 따라야 함\n",
    "\n",
    "* 단순선형회귀분석\n",
    "\n",
    " 단순의 의미? -> 하나의 독립변수만 존재하는 선형 회귀\n",
    "\n",
    " 데이터를 가장 잘 설명하는 직선 y = ax + b 를 찾는 과정 <- a는 회귀계수, b는 y절편\n",
    "\n",
    " 적절한 회귀계수 a와 절편 b를 찾는 과정\n",
    "\n",
    " 어떻게? -> 최소제곱법, 최소자승법\n",
    "\n",
    " 최소자승법?\n",
    "\n",
    " 잔차(실과 예측값의 차) 제곱의 합이 최소가 되는 지점으로 최적의 회귀선을 구하는 방식\n",
    "\n",
    " 핵심은 회귀선과 실제 데이터 간 차이를 최소화하기 위한 시도라는 것!\n",
    "\n",
    " cf) 최소자승법을 통해 구한 함수가 복잡하여 최솟값을 구하기 어려울 때 경사하강법 사용\n",
    "\n",
    " * 다중선형회귀분석\n",
    "\n",
    " 다중의 의미? -> 독립 변수가 2개 이상인 경우의 선형 회귀\n",
    "\n",
    " 독립변수 Xi가 2개인 경우 3차원 공간에 표현, 회귀선은 평면이 됨\n",
    "\n",
    " 단순과 마찬가지로 최소자승법 사용 가능, 관측치와 평면 간 차이가 잔차\n",
    "\n",
    " 변수가 2개보다 많은 경우 비슷한 느낌으로 확장\n",
    "\n",
    " 다중공선성 : 다중선형회귀 과정에서 중요한 체크사항\n",
    "\n",
    " 다중공선성은 회귀분석에서 독립변수들 간 상관관계가 큰 경우 발생\n",
    "\n",
    " 어떤 독립 변수가 종속 변수에 얼마나 영향을 미치는지 확실히 구분하기 어려움\n",
    "\n",
    " 다중공선성 확인 방법\n",
    "\n",
    " a. 상관계수 : 상관관계의 정도를 수치로 나타낸 것, -1과 1 사이에 존재\n",
    "\n",
    " 히트맵 혹은 corr()함수를 통해 상관계수가 확인 (pairplot과 같은 시각화로 산점도를 찍어 상관성을 눈으로 확인할 수도 있음)\n",
    "\n",
    " b. VIF지수 : 분산 팽창 인수, 회귀 모델의 결정계수 R square를 사용하여 계산\n",
    "\n",
    " VIF = 1 : 해당 독립 변수는 다른 변수와 상관관계가 전혀 없음\n",
    "\n",
    " VIF < 5 : 일반적으로 다중공선성 문제가 없다고 간주\n",
    "\n",
    " VIF > 5 : 다중공선성의 징후가 있을 수 있으며, 주의를 요함\n",
    "\n",
    " VIF > 10 : 다중공선성이 심각하다고 간주, 이 변수를 포함한 회귀모델은 불안정할 가능성 높음 -> 해당 변수를 제거하거나, 변수 간 상관관계를 줄이기 위한 조치 필요\n",
    "\n",
    " -> VIF가 높으면 다중공선성이 존재한다고 판단\n",
    "\n",
    " 다중공선성 대처 방법\n",
    "\n",
    " a. 변수 제거(변수 선택법) : 독립변수로서 사용할 변수를 선택하는 방법\n",
    "\n",
    " b. 변수 변환 : 변수들을 더하거나 빼 새로운 변수 생성 (독립변수끼리 더하거나 뺴도 문제가 없을 경우)\n",
    "\n",
    " c. 규제 선형 모델 활용 : 릿지, 라쏘, 엘라스틱넷 등의 방법을 통해 모델의 복잡도를 줄이는 방법\n",
    "\n",
    " d. PCA(주성분분석) : 데이터의 차원을 축소하는 데 사용되는 통계적 기법 / PCA는 고차원 데이터에서 중요한 정보를 최대한 보존하면서 데이터의 복잡성을 줄이는 것이 목표 -> 데이터의 차원이 높으면 분석과 시각화하기 어렵기 때문!\n",
    " \n",
    " cf. PCA 과정?\n",
    "\n",
    "  - Step1 : Centering by subtracting the mean from each data point (각 데이터포인트에서 평균 빼기)\n",
    "  - Step2 : Dividing by the standard deviation to make the data unit free. Data has variance 1 along each axis (데이터 표준화)\n",
    "  - Step3 : Compute eigenvalues and eigenvectors (arrows) of the data covariance matrix (ellipse) (공분산 행렬 계산, 고유값/고유벡터 계산)\n",
    "  - Step4 : Project data onto the principal subspace (데이터 주성분 공간으로 투영)\n",
    "  - Step5 : Undo the standardization and move projected data back into the original data space from (a) (표준화 해제, 주성분 공간에 투영된 데이터를 원래 데이터로 변환)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a42dc7d-c73d-4866-a674-2f0c4da545ce",
   "metadata": {},
   "source": [
    "4. 모델 평가방법\n",
    "\n",
    " 내가 만든 회귀 모델이 좋은 성능을 내는지, 올바른 회귀 모델인지 평가해야 함\n",
    "\n",
    " (모델 성능 및 유의성 평가)\n",
    "\n",
    " * (예측) 성능 평가 지표\n",
    "\n",
    "   a. 평균 제곱 오차(MSE) : 모델의 예측값과 실제 관측값 사이의 오차 제곱의 평균\n",
    "\n",
    "   b. 평균 절대 오차(MAE) : 모델의 예측값과 실제 관측값 사이의 절대값 오차의 평균\n",
    "\n",
    " * 설명력 평가 지표\n",
    "\n",
    "   a. 결정 계수(R-squared, R^2) : 모델이 설명하는 데이터의 총 변동 중에서 설명된 비율 / 모델이 데이터를 얼마나 잘 설명하는지 측정하는 지표 (0 < R^2 < 1) / 1에 가까울수록 모델이 데이터를 잘 설명함\n",
    "\n",
    " * 변수 유성 평가\n",
    "\n",
    "   a. t검정 : 각 독립 변수의 회귀계수가 유의한지 검정 / 유의성이 크다면 종속 변수에 영향을 주는 변수라고 판단 / t 통계량에 따른 p-value가 0.05보다 작다면 해당 변수는 유의하다고 판단"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
