{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe4b32d-af0e-4274-8e7f-e2f90c95ad0d",
   "metadata": {},
   "source": [
    "# 1. 분류란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad88c68-893d-4441-a2fa-c6f08ace48dc",
   "metadata": {},
   "source": [
    "## (1) 머신러닝: 지도 학습과 비지도 학습\n",
    "\n",
    "- **머신러닝** : 인공지능의 한 분야, <u>컴퓨터가 스스로 학습</u>할 수 있도록 도와주는 알고리즘 또는 기술을 개발하는 분야.\n",
    "\t- 인공지능 -> 머신러닝 -> 딥러닝\n",
    "\t- **지도 학습**(Supervised Learning) : 문제와 정답(label)을 모두 알려주고 학습시킴. -> 예측, 분류\n",
    "\t\t- 예측값(prediction)이 정답과 같아지도록 학습.\n",
    "\t\t- ex) 동물 사진을 보여주고, 어떤 게 고양이고 어떤 게 기린인지 알려줌.\n",
    "\t- **비지도 학습**(Unsupervised Learning) : 답을 가르쳐주지 않고 학습시킴. -> 연관 규칙, 군집화(clustering)\n",
    "\t\t- 데이터의 패턴 또는 데이터 간 유사도를 학습.\n",
    "\t\t- target/label이 없음, feature만 있는 데이터 사용.\n",
    "\t\t- 최근 집중적으로 연구되는 분야.\n",
    "\t\t- ex) 동물 사진들을 보고 비슷한 생김새의 동물 사진끼리 분류 (어떤 동물인지 답이 없음에도 사진을 종류별로 구분)\n",
    "\t- **강화 학습**(Reinforcement Learning) : 보상을 통해 상을 최대화 & 벌을 최소화하는 방향으로 학습시킴. -> 보상\n",
    "\t\t- 시행착오를 반복해 정답 찾음.\n",
    "- 컴퓨터의 일:\n",
    "\t1) 알고리즘을 이용해 데이터 분석\n",
    "\t2) 분석 결과를 스스로 학습\n",
    "\t3) 이를 바탕으로 판단 / 예측\n",
    "\n",
    "> **지도 학습과 비지도 학습의 차이**\n",
    "> 학습 데이터에 정답이 포함되어 있는지의 여부가 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a2883a-ac2e-481b-9ded-250e6764c222",
   "metadata": {},
   "source": [
    "## (2) 지도 학습: 회귀와 분류\n",
    "\n",
    "- 지도 학습의 과정\n",
    "\t1) **labeled data** : 독립변수(feature)와 종속변수(target/label)이 모두 존재하는 데이터. (= 입력 데이터와 그에 대응하는 출력값이 있는 데이터)\n",
    "\t2) labeled data를 training set과 test set으로 나눔.\n",
    "\t3) training set 통해 모델 학습 : feature를 통해 추정한 예측값(prediction)이 종속변수(target/label)와 같아지도록 훈련.\n",
    "\n",
    "- 회귀와 분류\n",
    "\t- 지도학습에는 회귀(연속적인 숫자값 예측)와 분류(입력 데이터를 주어진 항목들로 나눔)가 있음.\n",
    "\t- **회귀(Regression)** : 입력 데이터(X)를 기반으로 정답(y)를 잘 맞추는(fit) 함수를 찾는 문제.\n",
    "\t\t- -> 연속형 변수 예측\n",
    "\t- **분류(Classification)** : 기존 데이터가 어떤 label에 속하는지 패턴을 인식한 후 새롭게 관측된 데이터에 대한 label 판별.\n",
    "\t\t- -> 범주형 변수 예측\n",
    "\n",
    "> **회귀와 분류의 차이**\n",
    "> => 종속변수가 연속형이냐 범주형이냐에 따라 선택한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a737d-b5bf-42b6-8ae5-aced108c1200",
   "metadata": {},
   "source": [
    "## (3) 이진 분류와 다중 분류\n",
    "\n",
    "- **이진 분류(Binary Classification)** : 종속변수가 참/거짓의 값만을 가짐.\n",
    "- **다중 분류(Multiclass Classification)** : 종속변수가 가질 수 있는 값이 3개 이상."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643b661-d22b-4c55-aad2-ee9bd04086a0",
   "metadata": {},
   "source": [
    "# 2. 분류 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcbbdcf-e22c-4b8d-968c-e9a2bf7c1fc1",
   "metadata": {},
   "source": [
    "## (1) 로지스틱 회귀\n",
    "\n",
    "- **로지스틱 회귀(Logistic Regression)** : 이진 분류 문제를 푸는 대표적 알고리즘. 샘플이 특정 클래스에 속할 확률을 추정하는 것이 목표.\n",
    "\t- 독립변수의 선형 조합(LR)에 로지스틱 함수를 적용해 출력값을 0에서 1 사이로 변환하는 것.\n",
    "\t- ex) 이메일이 스팸인지 아닌지, 환자가 특정 질병을 가지고 있는지 아닌지\n",
    "- 이진 분류를 다중 선형 회귀로 풀려고 했을 때 발생하는 문제\n",
    "\t- 직선으로 이진 분류 문제를 풀 수 없음. S자 형태의 곡선 함수가 필요. 더해, 예측값은 0과 1 사이의 값을 가져야 하는데 직선으로 분류를 수행할 경우 무한대와 같은 수도 가질 수 있게 됨.\n",
    "\t- -> <u>1) 출력이 0과 1 사이이고</u>, <u>2) S자 형태로 그려지는 함수</u> 이용해야 함. => **시그모이드 함수**\n",
    "- **시그모이드 함수(Sigmoid function)** (=logistic function) : 출력이 0과 1 사이의 값을 가지면서 S자 형태로 그려지는 함수.\n",
    "\t- $$H(x) = \\frac{1}{1 + e^{-(wx+b)}} = \\text{sigmoid}(wx+b) = \\sigma(wx+b)$$\n",
    "\t- -> 출력값이 특정값 이상이면 1(True), 특정값 이하면 0(False)으로 정하면 이진 분류 작업에 이용 가능.\n",
    "- 시그모이드 함수의 가중치\n",
    "\t- 인공지능이 하는 일은 주어진 데이터에 적합한 **가중치 $w$와 $b$를 구하는 것**.\n",
    "\n",
    "```python\n",
    "# w의 변화에 따른 그래프 변화\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y1 = sigmoid(0.5*x)\n",
    "y2 = sigmoid(x)\n",
    "y3 = sigmoid(2*x)\n",
    "\n",
    "plt.plot(x, y1, 'r', linestyle='--') # w의 값이 0.5일때\n",
    "plt.plot(x, y2, 'g') # w의 값이 1일때\n",
    "plt.plot(x, y3, 'b', linestyle='--') # w의 값이 2일때\n",
    "plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- **odds** : 사건 A가 일어나지 않을 확률 대비 사건 A가 일어날 확률\n",
    "\t- $$\\text{odds} = \\frac{p(A)}{p(A^C)}$$\n",
    "\t- 로지스틱회귀에서 보다 *직관적인 해석*을 위해 활용할 수 있다. ( 오즈 공식의 양변에 로그를 취함 -> 비선형적인 결과를 선형 결과로 변환 : **로짓 변환**)\n",
    "\t- $$\\begin{array}{c}\n",
    "\t\\log (\\text{odds}) &=& \\log \\left ( \\frac{\\pi (X = x)}{1 - \\pi(X = x)} \\right )\n",
    "\t\\\\ &=& \\log \\left( \\frac{\\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}}{1 - \\frac{1}{1 + e^{\\beta_0 + \\beta_1 x}{}}} \\right)\n",
    "\t\\\\ &=& \\beta_0 + \\beta_1 x \\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea9a79c-8d78-49bb-ba78-f9ef2d89c043",
   "metadata": {},
   "source": [
    "## (2) Decision Tree\n",
    "\n",
    "- **결정 나무(Decision Tree)** : 조건에 따라 데이터를 분류. 최종적으로 데이터가 순수 label의 집합으로 구성될 때까지 분류를 반복하는 모델.\n",
    "- CART(Classification and Regression Tree) 알고리즘 : 임계값을 기준으로 데이터셋을 두 child로 나누는 알고리즘.\n",
    "\t- 임계값은 불순도(지니 계수)가 낮아지는 방향으로 나눈다.\n",
    "\t- 불순도 : 분류하려는 데이터 집합에서 서로 다른 범주가 섞여 있는 정도.\n",
    "\t- 지니 계수(Gini Index) : 불순도를 나타내며, 통계적 분산 정도를 정량화해서 표현한 값. 0과 1 사이의 값을 가짐.\n",
    "\t- Greedy Algorithm이기 때문에 항상 optimal한 결과를 도출하지 않는다.\n",
    "\n",
    "### 실제 학습 시 고려해야 할 것들\n",
    "\n",
    "**파라미터 설정**\n",
    "\n",
    "| 파라미터                       | 의미                                         |\n",
    "| -------------------------- | ------------------------------------------ |\n",
    "| `min_samples_split`        | 분할되기 위해 노드가 가져야 하는 최소 샘플 수                 |\n",
    "| `min_samples_leaf`         | 리프 노드가 가져야 하는 최소 샘플 수                      |\n",
    "| `min_weight_fraction_leaf` | 리프 노드가 가져야 하는 가중치가 부여된 전체 샘플 수에서 최소 샘플의 비율 |\n",
    "| `max_leaf_nodes`           | 리프 노드의 최대 개수                               |\n",
    "| `max_features`             | 각 노드에서 분할에 사용할 최대 feature 수                |\n",
    "\n",
    "**Prunning(가지치기)** = 불필요한 노드 지우기\n",
    "\n",
    "- 노드가 너무 많아지면 과적합이 될 확률이 높음 -> prunning을 통해 하부 트리를 제거해 일반화 성능을 높임.\n",
    "- 수행하면 트리 깊이와 결과 개수가 감소."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c51fb6-b885-4aea-8363-1d576479e254",
   "metadata": {},
   "source": [
    "## (3) 서포트 벡터 머신 (SVM)\n",
    "\n",
    "- **서포트 벡터 머신** : 클래스를 분류할 수 있는 최적 경계선을 찾아내는 알고리즘.\n",
    "\t- 명확히 분류 가능한 데이터 집단, 고차원 공간(다수의 feature)에서 유용\n",
    "- 구성\n",
    "\t- support vector : 구분하는 선과 가장 가까운 포인트\n",
    "\t- decision boundary : 집단을 구분하는 선\n",
    "\t- margin : 선과 각 점의 거리\n",
    "- 최적의 선 찾기 - **margin이 가장 큰 경우를 선택**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa5f8e-3731-4d9e-a92a-261c11bcbde6",
   "metadata": {},
   "source": [
    "## (4) KNN (K-Nearest Neighbor)\n",
    "\n",
    "- **KNN** : 데이터로부터 거리가 가까운 k개의 다른 데이터 레이블을 참조해 분류.\n",
    "\t- 특별히 학습이 필요하지 않다. 새로운 데이터의 주변 데이터들만을 이용해 classification 진행.\n",
    "- 계산 순서\n",
    "\t- 특징 벡터와 레이블로 이뤄진 데이터 준비.\n",
    "\t- 원하는 K값 설정 - 가장 가까운 이웃 개수. 보통 홀수로 설정.\n",
    "\t- 새로운 데이터와 기존 데이터들 간 거리 계산\n",
    "\t- 계산한 거리 중 가장 작은 거리 값 가지는 K개의 데이터 선택. -> 가장 가까운 이웃들\n",
    "\t- 이웃들 중 가장 많이 등장하는 클래스가 예측 결과.\n",
    "\n",
    "| 장점 | 단점 |\n",
    "|---|---|\n",
    "|- 훈련 필요 x<br> - 정보 손실 x |- 쿼리 처리 시간 $\\uparrow$ ( $\\because$ 사전 학습 한 모델 x)<br>- Not Robust : 이상치의 영향을 크게 받음|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81be706-91d5-44d1-8903-1fe107a0804d",
   "metadata": {},
   "source": [
    "# 3. 분류 평가 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fdb83a-ddce-4c03-828c-2e5135d213fa",
   "metadata": {},
   "source": [
    "## (1) 혼동 행렬\n",
    "\n",
    "- **혼동 행렬** : 분류 모델의 예측 결과를 정확한 예측과 잘못된 예측으로 구분해 나타낸 표 (행렬)\n",
    "\n",
    "|       |       | 예측 결과 |       |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "|       |       | **TRUE**  | **FALSE** |\n",
    "| **실제 정답** | **TRUE**  | TP    | FN    |\n",
    "|       | **FALSE** | FP    | TN    |\n",
    "\n",
    "- 혼동 행렬을 이용한 분류 모델 평가 지표\n",
    "\t- 정확도(Accuracy) : 모든 가능한 예측 중 참인 비율\n",
    "\t\t- (TP + TN) / (TP + TN + FP + FN)\n",
    "\t- 정밀도(Precision) : 참이라고 예측한 경우 실제 참의 비율\n",
    "\t\t- TP / (TP + FP)\n",
    "\t- 재현도(Recall) : 실제로 참인 경우 중 참으로 예측하는 비율\n",
    "\t\t- TP / (TP + FN)\n",
    "- Precision과 Recall은 trade-off 관계.\n",
    "- 문제의 특성에 따라 재현도, 정밀도 등 평가 지표 중 어떤 것이 중요한 지가 중요.\n",
    "- 정밀도 & 재현도 그래프의 교차점을 Threshold로 정하면 예측 오류 최소화 가능.\n",
    "\t- 그래프의 각 점은 분류 모델이 해당 임계값에서 정밀도와 재현도를 어떻게 예측했는지 표시 \n",
    "\t- 임계값에 따라 포기하는 면적이 달라지므로 Threshold 설정은 중요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe4589-31e7-4b17-b13e-954f1a484949",
   "metadata": {},
   "source": [
    "## (2) F1-Score\n",
    "\n",
    "- **F1-Score** : 정밀도와 재현율의 조화 평균\n",
    "\t- ML 모델 성능 평가하는 주요 지표."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5bb75-3a98-4a09-b719-cab058d4da28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (3) ROC / AUC Curve\n",
    "\n",
    "- **ROC Curve** : 얼마나 분류가 잘 되었는가를 보여주는 그래프.\n",
    "\t- True Positive Rate (TPR) : 참인 것들 중 참이라고 예측한 비율 (=Recall)\n",
    "\t- False Positive Rate (FPR) : 거짓인 것들 중 참이라고 잘못 예측한 비율\n",
    "- 완벽한 분류기는 불가. 현실적인 한계(비용, 시간 등)를 고려해 적절히 타협한 곡선 도출해야 함.\n",
    "\n",
    "- **AUC Curve** : ROC와 x축 사이의 면적.\n",
    "\t- 1에 가까울수록 분류 성능이 좋은 것에 해당."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae5421-972d-4d31-84c7-902ab016f498",
   "metadata": {},
   "source": [
    "## (4) 다중 분류 평가 지표\n",
    "\n",
    "이전까지는 모두 이진 분류 평가 지표.\n",
    "\n",
    "- **다중 분류 평가 지표** : 이진 분류 평가 지표를 사용해 클래스별로 점수 구하고, 적절히 평균 내는 것.\n",
    "\t- Macro average : 클래스별로 구한 평가 지표 평균\n",
    "\t\t- -> 모든 라벨이 유사한 중요도 가질 경우.\n",
    "\t- Weighted average : 클래스별로 구한 평가 지표 가중 평균\n",
    "\t\t- -> 샘플이 많은 라벨에 중요도 $\\uparrow$ \n",
    "\t- Micro average : **모든 클래스 예측 결과를 더해** 전체적인 성능 평가하는 지표\n",
    "\t\t- -> 라벨 상관 없이 전체 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53114f5-db68-4bf6-a006-be36ab5904f2",
   "metadata": {},
   "source": [
    "# 4. 하이퍼파라미터 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59562a-73ef-4b22-ada5-39ab36206adc",
   "metadata": {},
   "source": [
    "## (1) 하이퍼파라미터 최적화\n",
    "\n",
    "- **하이퍼파라미터** : 학습 시작 전에 사용자가 직접 설정하는 변수\n",
    "\t- ex) decision tree의 `max_depth`\n",
    "- 하이퍼파라미터 최적화 : 적절한 하이퍼파라미터를 찾아 모델 성능 높이는 것.\n",
    "\n",
    "> **하이퍼파라미터 최적화 과정**\n",
    "> 1. 최적 값을 찾을 하이퍼파라미터 탐색 범위 설정\n",
    "> 2. 평가 지표 계산 함수(성능 평가 함수, 하이퍼파라미터를 인수로 받아 평가지표 계산하는 함수) 정의\n",
    "> 3. 1에서 샘플링한 하이퍼파라미터 값을 사용해 검증 데이터로 정확도 평가\n",
    "> 4. 위 단계를 정해진 횟수만큼 반복, 정확도 결과 보고 하이퍼파라미터 범위 좁힘."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b296d74-42ed-4c4c-8d82-58b1d0d5c682",
   "metadata": {},
   "source": [
    "## (2) 하이퍼파라미터 최적화 방법\n",
    "\n",
    "- **Grid Search** : 정해진 범위에서 하이퍼파라미터를 모두 순회하며 가장 좋은 성능 내는 값 찾음.\n",
    "\t- sklearn의 `GridSearchCV`\n",
    "\t- 장점 : 범위 넓고 스텝이 작을수록 꼼꼼히 탐색 -> 정확한 최적해.\n",
    "\t- 단점 : 시간 소요 $\\uparrow$ \n",
    "\t- => 넓은 범위, 큰 스텝으로 범위를 좁힘\n",
    "- **Random Search** : 정해진 범위에서 하이퍼파라미터를 무작위로 탐색\n",
    "\t- sklearn의 `RandomSearchCV`\n",
    "\t- 장점 : Grid Search보다 빠름.\n",
    "\t- 단점 : 무작위 -> 정확도가 떨어짐. => 잘 사용하지 않음.\n",
    "- **Bayesian Optimization** : 사전 정보를 바탕으로 하이퍼파라미터값을 확률적으로 추정하며 탐색\n",
    "\t- Gausian Process를 기반으로 만든 모델. 다수의 하이퍼파라미터에 대해 Aquisition Function 적용 시 가장 큰 값이 나올 확률이 높은 지점 찾아냄.\n",
    "\n",
    "> Optuna 등 라이브러리를 사용해 하이퍼파라미터 최적화를 자동화할 수 있음."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
